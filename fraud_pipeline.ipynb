{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71d39d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ff2971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading CSV's\n",
    "claims = pd.read_csv('dataset/synthetic_claims.csv')\n",
    "patients = pd.read_csv('dataset/synthetic_patients.csv')\n",
    "procedures = pd.read_csv('dataset/synthetic_procedures.csv')\n",
    "providers = pd.read_csv('dataset/synthetic_providers.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a0f1160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = claims \\\n",
    "    .merge(patients, on='patient_id', how='left') \\\n",
    "    .merge(providers, on='provider_id', how='left') \\\n",
    "    .merge(procedures, on='procedure_code', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269e725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating fraud flags\n",
    "df['is_outlier'] = df['claim_amount'] > 9555.79\n",
    "df['is_repeated_147'] = df['claim_amount'] == 147.95\n",
    "df['missing_diag'] = df['diagnosis_code'].isnull() | (df['diagnosis_code'].str.strip() == '')\n",
    "df['is_suspicious'] = df[['is_outlier', 'is_repeated_147', 'missing_diag']].any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3e083de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving as csv\n",
    "df.to_csv('fraud_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e7500",
   "metadata": {},
   "source": [
    "## Validating SQL Findings with Python (Pandas + Matplotlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d7815",
   "metadata": {},
   "source": [
    "To ensure the accuracy and reproducibility of my SQL-based fraud detection analysis, I re-implemented the core logic in Python using Pandas. This enabled me to confirm that suspicious billing patterns, high-risk providers, and missing data indicators were consistently detected across platforms.\n",
    "\n",
    "All findings from the SQL scripts (e.g., `claims_fraud_detection.sql`) were programmatically validated using the same thresholds and grouping logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34b1813d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Suspicious vs Legit Claims:\n",
      " is_suspicious\n",
      "Suspicious    443\n",
      "Legit          57\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Suspicious vs Legit Claims (You may have an 'is_suspicious' flag added during processing)\n",
    "suspicious_summary = df['is_suspicious'].value_counts().rename(index={True: 'Suspicious', False: 'Legit'})\n",
    "print(\"ðŸ”¹ Suspicious vs Legit Claims:\\n\", suspicious_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "691bdd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Repeated $147.95 Claims Count: 419\n"
     ]
    }
   ],
   "source": [
    "# 2. Repeated $147.95 Claim Pattern (SQL: HAVING frequency > 50)\n",
    "repeated_147_count = df[df['claim_amount'] == 147.95].shape[0]\n",
    "print(\"\\nðŸ”¹ Repeated $147.95 Claims Count:\", repeated_147_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e373309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Top Diagnosis Codes by Avg Claim:\n",
      "                 count         mean       max\n",
      "diagnosis_code                              \n",
      "D001               74  2545.818649  11532.04\n",
      "D002               86  1701.112791  11698.86\n",
      "D004              114  1328.557193  11532.07\n",
      "D003               39   990.900256   9683.64\n",
      "D005              187   474.463743   8156.92\n"
     ]
    }
   ],
   "source": [
    "# 3. Average Claim Amount by Diagnosis (SQL: GROUP BY diagnosis_code)\n",
    "avg_claim_by_diag = df.groupby('diagnosis_code')['claim_amount'].agg(['count', 'mean', 'max']).sort_values(by='mean', ascending=False)\n",
    "print(\"\\nðŸ”¹ Top Diagnosis Codes by Avg Claim:\\n\", avg_claim_by_diag.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6c32201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Outlier Claims (> $8284.97):\n",
      "     claim_id  claim_amount\n",
      "117     C007       9683.64\n",
      "118     C010       9683.93\n",
      "119     C008       9683.41\n",
      "120     C009       9683.57\n",
      "144     C034      11209.51\n"
     ]
    }
   ],
   "source": [
    "# 4. High-Value Outlier Claims (SQL: claim_amount > 8284.97)\n",
    "outlier_claims = df[df['claim_amount'] > 8284.97]\n",
    "print(\"\\nðŸ”¹ Outlier Claims (> $8284.97):\\n\", outlier_claims[['claim_id', 'claim_amount']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7031be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Missing Diagnosis Claims:\n",
      " Empty DataFrame\n",
      "Columns: [claim_id, diagnosis_code]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 5. Missing or Blank Diagnosis (SQL: WHERE diagnosis_code IS NULL OR TRIM(diagnosis_code) = '')\n",
    "missing_diag_claims = df[df['diagnosis_code'].isnull() | (df['diagnosis_code'].str.strip() == '')]\n",
    "print(\"\\nðŸ”¹ Missing Diagnosis Claims:\\n\", missing_diag_claims[['claim_id', 'diagnosis_code']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4d14ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Claims from Flagged Providers:\n",
      " Empty DataFrame\n",
      "Columns: [claim_id, provider_id, claim_amount]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 6. Providers with High Avg Claim Value (SQL: HAVING AVG(claim_amount) > 10000)\n",
    "provider_avg_claims = df.groupby('provider_id')['claim_amount'].mean()\n",
    "flagged_providers = provider_avg_claims[provider_avg_claims > 10000].index.tolist()\n",
    "claims_from_flagged_providers = df[(df['provider_id'].isin(flagged_providers)) & (df['claim_amount'] > 8284.97)]\n",
    "print(\"\\nðŸ”¹ Claims from Flagged Providers:\\n\", claims_from_flagged_providers[['claim_id', 'provider_id', 'claim_amount']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
